{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e6fc05-42e9-44f6-9647-b1ff7a57dacd",
   "metadata": {},
   "source": [
    "# Cell Typing of Segmented Xenium Data for NSCLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e65e1c-7052-471c-9002-7745b6bbfa71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:11:57.367507Z",
     "iopub.status.busy": "2025-01-02T22:11:57.367169Z",
     "iopub.status.idle": "2025-01-02T22:11:57.397059Z",
     "shell.execute_reply": "2025-01-02T22:11:57.396684Z",
     "shell.execute_reply.started": "2025-01-02T22:11:57.367489Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2effdc3a-5867-45ab-93d2-f3613077847c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:11:57.607758Z",
     "iopub.status.busy": "2025-01-02T22:11:57.607515Z",
     "iopub.status.idle": "2025-01-02T22:13:19.511106Z",
     "shell.execute_reply": "2025-01-02T22:13:19.510667Z",
     "shell.execute_reply.started": "2025-01-02T22:11:57.607743Z"
    }
   },
   "outputs": [],
   "source": [
    "from requirements import *\n",
    "from segger.data.parquet._utils import (\n",
    "    filter_transcripts,\n",
    "    load_settings,\n",
    ")\n",
    "from sg_utils.tl.phenograph_rapids import phenograph_rapids\n",
    "from sg_utils.tl.xenium_utils import anndata_from_transcripts\n",
    "from sg_utils.pp.preprocess_rapids import *\n",
    "from sg_utils.pl.plot_embedding import plot_embedding\n",
    "from sg_utils.tl.get_group_markers import *\n",
    "from sg_utils.pl.plot_group_markers import plot_group_markers\n",
    "import celltypist as ct\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f54161-cad0-4a5b-8a54-5bc305cce54f",
   "metadata": {},
   "source": [
    "## Build Cell Typist Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "68b3d23d-1421-488d-963a-93992a770af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T01:25:05.237003Z",
     "iopub.status.busy": "2024-11-08T01:25:05.236522Z",
     "iopub.status.idle": "2024-11-08T01:26:01.751244Z",
     "shell.execute_reply": "2024-11-08T01:26:01.750522Z",
     "shell.execute_reply.started": "2024-11-08T01:25:05.236984Z"
    }
   },
   "outputs": [],
   "source": [
    "# NSCLC Atlas\n",
    "ad_atlas = sc.read_h5ad(data_dir / 'h5ads/core_nsclc_atlas_panel_only.h5ad')\n",
    "\n",
    "# Re-normalize counts to 10K total\n",
    "ad_atlas.X = ad_atlas.layers['count'].copy()\n",
    "sc.pp.downsample_counts(ad_atlas, counts_per_cell=100)\n",
    "ad_atlas.layers['norm_100'] = ad_atlas.X.copy()\n",
    "sc.pp.normalize_total(ad_atlas, layer='norm_100', target_sum=1e2)\n",
    "\n",
    "# Logarthmize\n",
    "ad_atlas.layers['lognorm_100'] = ad_atlas.layers['norm_100'].copy()\n",
    "if 'log1p' in ad_atlas.uns:\n",
    "    del ad_atlas.uns['log1p']\n",
    "sc.pp.log1p(ad_atlas, layer='lognorm_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0529e733-86f7-41c2-a860-42e51e3c3a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T01:31:56.182414Z",
     "iopub.status.busy": "2024-11-08T01:31:56.181923Z",
     "iopub.status.idle": "2024-11-08T01:32:14.397103Z",
     "shell.execute_reply": "2024-11-08T01:32:14.396500Z",
     "shell.execute_reply.started": "2024-11-08T01:31:56.182396Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subsample using more granular cell types (to not lose any one cell type)\n",
    "# But transfer labels using the compartment labels\n",
    "gb = ad_atlas.obs.groupby('cell_type')\n",
    "sample = gb.sample(2000, replace=True).index.drop_duplicates()\n",
    "\n",
    "# Predict on log counts\n",
    "ad_atlas.X = ad_atlas.layers['lognorm_1k']\n",
    "with HiddenPrints():\n",
    "    ct_model = ct.train(\n",
    "        ad_atlas[sample],\n",
    "        labels='cell_compartment',\n",
    "        check_expression=False,\n",
    "        n_jobs=32,\n",
    "        max_iter=100,\n",
    "    )\n",
    "\n",
    "ct_model.write(data_dir / 'NSCLC_celltypist_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f3056-f943-42c5-a9fb-9cd06812db2c",
   "metadata": {},
   "source": [
    "## Transcripts to AnnData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45cda1f-60db-4e18-b10f-c3d26e983fd6",
   "metadata": {},
   "source": [
    "*Note*: Below, I filter using 'min_counts_per_cell' = 10. \n",
    "This is fairly low, even for Xenium data. However, for this analysis, my\n",
    "primary concern is ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62d3789c-6696-4761-a561-a1e2d07e486e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:51:47.505016Z",
     "iopub.status.busy": "2024-11-11T22:51:47.504552Z",
     "iopub.status.idle": "2024-11-11T22:51:47.573284Z",
     "shell.execute_reply": "2024-11-11T22:51:47.572887Z",
     "shell.execute_reply.started": "2024-11-11T22:51:47.504998Z"
    }
   },
   "outputs": [],
   "source": [
    "# Segmentation columns to compare\n",
    "segmentations = {\n",
    "    'segger_cell_id_HDE46PBXJB': 'Segger+',\n",
    "    'baysor_cell_id_c=0.5': 'Baysor, c=0.5',\n",
    "    '10x_cell_id': '10X',\n",
    "    'cellpose_cell_id': 'CellPose',\n",
    "    '10x_nucleus_id': '10X Nucleus',\n",
    "    'baysor_cell_id_c=0.7': 'Baysor, c=0.7',\n",
    "    'baysor_cell_id_c=0.9': 'Baysor, c=0.9',\n",
    "    'segger_cell_id_3Q6EISGCD9': 'Segger',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e5131d-01a1-4ef9-95cb-8c245cf5ba57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:42:29.979326Z",
     "iopub.status.busy": "2024-11-11T22:42:29.979042Z",
     "iopub.status.idle": "2024-11-11T22:43:26.850624Z",
     "shell.execute_reply": "2024-11-11T22:43:26.850065Z",
     "shell.execute_reply.started": "2024-11-11T22:42:29.979311Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in all transcripts\n",
    "transcripts = pd.read_parquet(data_dir / 'labeled_transcripts.parquet')\n",
    "\n",
    "# Filter control probes and low QV probes\n",
    "xe_settings = load_settings('xenium')\n",
    "\n",
    "transcripts = filter_transcripts(\n",
    "    transcripts,\n",
    "    label=xe_settings.transcripts.label,\n",
    "    filter_substrings=xe_settings.transcripts.filter_substrings,\n",
    "    min_qv=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7028eb3f-180d-4dc8-a1ea-51451b0e97af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:51:53.274238Z",
     "iopub.status.busy": "2024-11-11T22:51:53.273892Z",
     "iopub.status.idle": "2024-11-11T22:53:41.167222Z",
     "shell.execute_reply": "2024-11-11T22:53:41.166799Z",
     "shell.execute_reply.started": "2024-11-11T22:51:53.274221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:47<00:00, 13.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# Add centroid locations\n",
    "for seg_col in tqdm(segmentations.keys()):\n",
    "\n",
    "    # Read in AnnData\n",
    "    filepath = data_dir / f'h5ads/{seg_col}.h5ad'\n",
    "    ad = sc.read_h5ad(filepath)\n",
    "    \n",
    "    # Set centroid locations\n",
    "    idx = ad.obs.index.astype(transcripts[seg_col].dtype)\n",
    "    mask = transcripts[seg_col].isin(idx)\n",
    "    \n",
    "    # Subset Segger data to high-confidence transcripts\n",
    "    if 'segger' in seg_col:\n",
    "        score_col = seg_col.replace('cell_id', 'score')\n",
    "        mask &= transcripts[score_col].gt(0.75)\n",
    "    \n",
    "    cols = ['x_location', 'y_location']\n",
    "    tx = cudf.from_pandas(transcripts.loc[mask, [seg_col] + cols])\n",
    "    centroids = tx.groupby(seg_col)[cols].mean()\n",
    "    ad.obsm['X_spatial'] = centroids.loc[idx].values\n",
    "\n",
    "    # Write back to file and clean up\n",
    "    ad.write_h5ad(filepath)\n",
    "    \n",
    "    del tx, centroids\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ff51da-e670-4463-869c-660abde19709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:54:40.112966Z",
     "iopub.status.busy": "2024-11-08T20:54:40.112720Z",
     "iopub.status.idle": "2024-11-08T20:58:05.305550Z",
     "shell.execute_reply": "2024-11-08T20:58:05.305079Z",
     "shell.execute_reply.started": "2024-11-08T20:54:40.112949Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done: 100%|██████████| 6/6 [02:59<00:00, 29.85s/it]         \n"
     ]
    }
   ],
   "source": [
    "# Convert to AnnData and preprocess\n",
    "for seg_col in segmentations.keys():\n",
    "\n",
    "    # Subset Segger data to high-confidence transcripts\n",
    "    mask = np.full(transcripts.shape[0], True)\n",
    "    if 'segger' in seg_col:\n",
    "        score_col = seg_col.replace('cell_id', 'score')\n",
    "        mask &= transcripts[score_col].gt(0.75)\n",
    "    \n",
    "    # Transcripts to anndata\n",
    "    ad = anndata_from_transcripts(\n",
    "        transcripts[mask],\n",
    "        cell_label=seg_col,\n",
    "        gene_label='feature_name',\n",
    "    )\n",
    "\n",
    "    # Add raw counts before filtering\n",
    "    ad.uns['raw_counts'] = dict(\n",
    "        index=ad.obs.index.tolist(),\n",
    "        count=ad.raw.X.A.sum(1),\n",
    "    )\n",
    "    \n",
    "    # Preprocess\n",
    "    threshold = 5 #np.quantile(ad.uns['raw_counts']['count'], 0.05)\n",
    "    preprocess_rapids(\n",
    "        ad,\n",
    "        filter_min_counts=threshold,\n",
    "        pca_total_var=0.75,\n",
    "        umap_min_dist=0.25,\n",
    "        umap_n_epochs=4000,\n",
    "        pca_layer='lognorm',\n",
    "        knn_neighbors=20,\n",
    "        phenograph_resolution=1,\n",
    "    )\n",
    "\n",
    "    # Save to file\n",
    "    ad.write_h5ad(data_dir / f'h5ads/{seg_col}_alt.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2932455a-de5f-4158-a481-b6b055f5c05b",
   "metadata": {},
   "source": [
    "## Cell Type with CellTypist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47305b4c-768f-4e72-80bc-85cb51edf378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:58:05.306848Z",
     "iopub.status.busy": "2024-11-08T20:58:05.306512Z",
     "iopub.status.idle": "2024-11-08T20:58:32.629462Z",
     "shell.execute_reply": "2024-11-08T20:58:32.629010Z",
     "shell.execute_reply.started": "2024-11-08T20:58:05.306830Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:25<00:00, 25.86s/it]\n"
     ]
    }
   ],
   "source": [
    "ct_model = ct.Model.load(str(data_dir / 'NSCLC_celltypist_model.pkl'))\n",
    "\n",
    "# Cell type each segmentation\n",
    "for seg_col in tqdm(segmentations.keys()):\n",
    "    \n",
    "    # Read in AnnData\n",
    "    filepath = data_dir / f'h5ads/{seg_col}.h5ad'\n",
    "    ad = sc.read_h5ad(filepath)\n",
    "    \n",
    "    # Re-normalize consistent with CellTypist model\n",
    "    ad.layers['norm_1k'] = ad.raw.X.copy()\n",
    "    sc.pp.normalize_total(ad, layer='norm_1k', target_sum=1e2)\n",
    "    ad.layers['lognorm_1k'] = ad.layers['norm_1k'].copy()\n",
    "    if 'log1p' in ad.uns: del ad.uns['log1p']\n",
    "    sc.pp.log1p(ad, layer='lognorm_1k')\n",
    "\n",
    "    phenograph_rapids(ad, min_size=1, resolution=1)\n",
    "    \n",
    "    # Cell type\n",
    "    with HiddenPrints():\n",
    "        ad.X = ad.layers['lognorm_1k']\n",
    "        preds = ct.annotate(\n",
    "            ad, model=ct_model, majority_voting=True,\n",
    "            over_clustering='phenograph_cluster',\n",
    "            min_prop=0.5,\n",
    "        )\n",
    "\n",
    "    # Label AnnData\n",
    "    ad.obs['celltypist_label'] = preds.predicted_labels['predicted_labels']\n",
    "    ad.obs['celltypist_label_cluster'] = preds.predicted_labels['majority_voting']\n",
    "    ad.obs['celltypist_probability'] = preds.probability_matrix.max(1)\n",
    "    for col in preds.probability_matrix.columns:\n",
    "        ad.obs[f'{col} Probability'] = preds.probability_matrix[col]\n",
    "    entropy = sp.stats.entropy(preds.probability_matrix, axis=1)\n",
    "    ad.obs['celltypist_entropy'] = entropy\n",
    "\n",
    "    # Cleanup\n",
    "    del ad.layers['lognorm_1k'], ad.layers['norm_1k']\n",
    "\n",
    "    ad.write_h5ad(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ecdd1-a0bc-4151-9f2e-bba5a51e4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
